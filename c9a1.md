Practical Machine Learning - Prediction Assignment Writeup

========================================================

The goal of your project is to predict the manner in which users did the exercise.
This is the "classe" variable in the training set. 


Getting Data

The training data for this project are available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


```r
training <- read.csv("C:/Users/Tommy Chan/c8a1/pml-training.csv", na.strings = c("NA", 
    ""))
testing <- read.csv("C:/Users/Tommy Chan/c8a1/pml-testing.csv", na.strings = c("NA", 
    ""))
```



Discarding columns with not enough data


```r
var <- names(training)[apply(training, 2, function(x) table(is.na(x))[1] == 
    19622)]
training02 <- training[, var]
testing02 <- testing[, c(var[-length(var)], names(testing)[length(testing)])]

unneedolIndex <- grep("new_window|num_window|X|timestamp|user_name", colnames(training02))
training03 <- training02[, -c(unneedolIndex)]
testing03 <- testing02[, -c(unneedolIndex)]
```



Training a model 

randomForest is used as it is one of the best classification 


```r
library(caret)
```

```
## Loading required package: lattice
## Loading required package: ggplot2
```

```r
yy = createDataPartition(training03$classe, p = 0.7, list = FALSE)
trainPart = training03[yy, ]
testPart = training03[-yy, ]

library(randomForest)
```

```
## randomForest 4.6-7
## Type rfNews() to see new features/changes/bug fixes.
```

```r
resultModel <- randomForest(classe ~ ., data = trainPart)
```



cross validation,  out of sample error


```r
aTestingLabelsPred <- predict(resultModel, newdata = testPart)
aConfusionMatrix <- confusionMatrix(aTestingLabelsPred, testPart$classe)
aConfusionMatrix
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1674   11    0    0    0
##          B    0 1126   16    0    0
##          C    0    2 1008   11    0
##          D    0    0    2  952    2
##          E    0    0    0    1 1080
## 
## Overall Statistics
##                                        
##                Accuracy : 0.992        
##                  95% CI : (0.99, 0.994)
##     No Information Rate : 0.284        
##     P-Value [Acc > NIR] : <2e-16       
##                                        
##                   Kappa : 0.99         
##  Mcnemar's Test P-Value : NA           
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             1.000    0.989    0.982    0.988    0.998
## Specificity             0.997    0.997    0.997    0.999    1.000
## Pos Pred Value          0.993    0.986    0.987    0.996    0.999
## Neg Pred Value          1.000    0.997    0.996    0.998    1.000
## Prevalence              0.284    0.194    0.174    0.164    0.184
## Detection Rate          0.284    0.191    0.171    0.162    0.184
## Detection Prevalence    0.286    0.194    0.173    0.162    0.184
## Balanced Accuracy       0.999    0.993    0.990    0.993    0.999
```



Out-of-sample error


```r
(1 - aConfusionMatrix$overall["Accuracy"])[[1]]
```

```
## [1] 0.007647
```



With the prediction model, we use it to predict 20 different test cases : 


```r
answers <- predict(resultModel, testing03)

pml_write_files = function(x) {
    n = length(x)
    for (i in 1:n) {
        filename = paste0("problem_id_", i, ".txt")
        write.table(x[i], file = filename, quote = FALSE, row.names = FALSE, 
            col.names = FALSE)
    }
}
pml_write_files(answers)
```



The Result 


```r
answers
```

```
##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E
```

